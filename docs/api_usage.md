# Ensemble-Hub API ä½¿ç”¨æŒ‡å—

Enhanced API v2.0 æ”¯æŒçµæ´»çš„é›†æˆæ–¹æ³•é€‰æ‹©å’Œé…ç½®ã€‚

## ğŸš€ å¯åŠ¨ API æœåŠ¡å™¨

### åŸºç¡€å¯åŠ¨
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹å¯åŠ¨
python -m ensemblehub.api

# æˆ–ä½¿ç”¨ uvicornï¼ˆä»…æ”¯æŒæœåŠ¡å™¨é…ç½®ï¼Œä¸æ”¯æŒé›†æˆæ–¹æ³•é…ç½®ï¼‰
uvicorn ensemblehub.api:app --host 0.0.0.0 --port 8000
```

### å‘½ä»¤è¡Œé…ç½®å¯åŠ¨
**æ³¨æ„ï¼šé›†æˆæ–¹æ³•é…ç½®ä»…åœ¨ä½¿ç”¨ `python -m ensemblehub.api` å¯åŠ¨æ—¶æœ‰æ•ˆï¼Œuvicorn å¯åŠ¨æ–¹å¼ä¸æ”¯æŒè¿™äº›è‡ªå®šä¹‰å‚æ•°ã€‚**

```bash
# é…ç½®æœåŠ¡å™¨åœ°å€å’Œç«¯å£
python -m ensemblehub.api --host 0.0.0.0 --port 8080

# é…ç½®æ¨¡å‹é€‰æ‹©å’Œé›†æˆæ–¹æ³•
python -m ensemblehub.api --model_selection_method zscore --ensemble_method progressive

# é…ç½®å¾ªç¯æ¨ç†ï¼ˆä¸ä½¿ç”¨æ¨¡å‹é€‰æ‹©ï¼‰
python -m ensemblehub.api --model_selection_method all --ensemble_method loop --max_rounds 5

# é…ç½®æ¸è¿›å¼é›†æˆ
python -m ensemblehub.api --ensemble_method progressive --progressive_mode length \
  --length_thresholds 50,100,200 --max_rounds 3

# é…ç½®éšæœºé€‰æ‹©é›†æˆ
python -m ensemblehub.api --model_selection_method all --ensemble_method random --max_rounds 3

# é…ç½®å¾ªç¯é€‰æ‹©é›†æˆï¼ˆè½®è¯¢æ¨¡å¼ï¼‰
python -m ensemblehub.api --model_selection_method all --ensemble_method loop \
  --max_rounds 5 --max_repeat 2

# é…ç½®è‡ªå®šä¹‰æ¨¡å‹
python -m ensemblehub.api --model_specs '[{"path":"model1","engine":"hf"},{"path":"model2","engine":"hf"}]'

# å®Œæ•´é…ç½®ç¤ºä¾‹
python -m ensemblehub.api \
  --host 0.0.0.0 --port 8080 \
  --model_selection_method zscore \
  --ensemble_method progressive \
  --progressive_mode mixed \
  --length_thresholds 100,200 \
  --special_tokens "<step>,<think>" \
  --max_rounds 5 \
  --score_threshold -2.0 \
  --max_repeat 3
```

### å¯ç”¨çš„å‘½ä»¤è¡Œå‚æ•°

#### æœåŠ¡å™¨é…ç½®
- `--host`: æœåŠ¡å™¨ä¸»æœºåœ°å€ (é»˜è®¤: 127.0.0.1)
- `--port`: æœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8000)

#### é›†æˆé…ç½®
- `--model_selection_method`: æ¨¡å‹é€‰æ‹©æ–¹æ³•
  - `zscore`: åŸºäº Z-score çš„ç»Ÿè®¡é€‰æ‹© (é»˜è®¤)
  - `all`: ä½¿ç”¨æ‰€æœ‰æ¨¡å‹
  - `random`: éšæœºé€‰æ‹©æ¨¡å‹
- `--ensemble_method`: é›†æˆæ–¹æ³•
  - `simple`: ç®€å•å¥–åŠ±æ¨¡å‹é›†æˆ (é»˜è®¤)
  - `progressive`: æ¸è¿›å¼é›†æˆ
  - `random`: éšæœºé›†æˆ
  - `loop`: å¾ªç¯/è½®è¯¢é›†æˆ
- `--max_rounds`: æœ€å¤§æ¨ç†è½®æ•° (é»˜è®¤: 10)
- `--score_threshold`: åˆ†æ•°é˜ˆå€¼ (é»˜è®¤: -1.5)
- `--max_repeat`: æœ€å¤§é‡å¤æ¬¡æ•° (é»˜è®¤: 3)

#### æ¸è¿›å¼é›†æˆç‰¹å®šé…ç½®
- `--progressive_mode`: æ¸è¿›æ¨¡å¼
  - `length`: åŸºäºé•¿åº¦çš„æ¨¡å‹åˆ‡æ¢
  - `token`: åŸºäºç‰¹æ®Šä»¤ç‰Œçš„æ¨¡å‹åˆ‡æ¢
  - `mixed`: æ··åˆæ¨¡å¼ (é»˜è®¤)
- `--length_thresholds`: é•¿åº¦é˜ˆå€¼åˆ—è¡¨ï¼Œé€—å·åˆ†éš” (å¦‚: 50,100,200)
- `--special_tokens`: ç‰¹æ®Šä»¤ç‰Œåˆ—è¡¨ï¼Œé€—å·åˆ†éš” (å¦‚: <step>,<think>)

#### æ¨¡å‹é…ç½®
- `--model_specs`: JSON æ ¼å¼çš„æ¨¡å‹è§„æ ¼åˆ—è¡¨

æœåŠ¡å¯åŠ¨åè®¿é—®ï¼š
- API æ–‡æ¡£: http://localhost:8000/docs
- å¥åº·æ£€æŸ¥: http://localhost:8000/status

## ğŸ“‹ ä¸»è¦ API ç«¯ç‚¹

### 1. åŸºç¡€ä¿¡æ¯
- `GET /` - API ä¿¡æ¯å’Œç«¯ç‚¹åˆ—è¡¨
- `GET /status` - å¥åº·æ£€æŸ¥å’Œå¯ç”¨æ–¹æ³•
- `GET /v1/ensemble/methods` - åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é›†æˆæ–¹æ³•

### 2. é…ç½®ç®¡ç†
- `GET /v1/ensemble/config` - è·å–å½“å‰é…ç½®
- `POST /v1/ensemble/config` - æ›´æ–°é…ç½®

### 3. æ¨ç†ç«¯ç‚¹
- `POST /v1/chat/completions` - OpenAI å…¼å®¹çš„èŠå¤©å®Œæˆ
- `POST /v1/loop/completions` - ä¸“ç”¨å¾ªç¯æ¨ç†ç«¯ç‚¹ï¼ˆè½®è¯¢æ¨¡å¼ï¼‰
- `POST /v1/ensemble/inference` - ç›´æ¥é›†æˆæ¨ç†
- `POST /v1/ensemble/batch` - æ‰¹é‡æ¨ç†

### 4. é¢„è®¾ç«¯ç‚¹
- `POST /v1/ensemble/presets/simple` - ç®€å•é›†æˆ
- `POST /v1/ensemble/presets/selection_only` - ä»…æ¨¡å‹é€‰æ‹©
- `POST /v1/ensemble/presets/aggregation_only` - ä»…è¾“å‡ºèšåˆ

## ğŸ”§ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€èŠå¤©å®Œæˆï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰

```bash
curl -X POST "http://localhost:8000/v1/chat/completions" \
-H "Content-Type: application/json" \
-d '{
  "model": "ensemble",
  "prompt": "What is 2+2?",
  "max_tokens": 100
}'
```

### 2. å¸¦é›†æˆé…ç½®çš„èŠå¤©å®Œæˆ

```bash
curl -X POST "http://localhost:8000/v1/chat/completions" \
-H "Content-Type: application/json" \
-d '{
  "model": "ensemble",
  "prompt": "Solve this math problem: 15 Ã— 23",
  "max_tokens": 200,
  "ensemble_config": {
    "model_selection_method": "zscore",
    "aggregation_method": "reward_based",
    "aggregation_level": "sentence",
    "use_model_selection": true,
    "use_output_aggregation": true
  }
}'
```

### 3. å¾ªç¯æ¨ç†ç«¯ç‚¹ï¼ˆè½®è¯¢æ¨¡å¼ï¼‰

```bash
curl -X POST "http://localhost:8000/v1/loop/completions" \
-H "Content-Type: application/json" \
-d '{
  "model": "ensemble",
  "prompt": "è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†",
  "max_tokens": 300,
  "ensemble_config": {
    "max_rounds": 5,
    "score_threshold": -1.5
  }
}'
```

### 4. ç›´æ¥é›†æˆæ¨ç†

```bash
curl -X POST "http://localhost:8000/v1/ensemble/inference" \
-H "Content-Type: application/json" \
-d '{
  "instruction": "You are a helpful math tutor.",
  "input": "Explain how to solve quadratic equations",
  "ensemble_config": {
    "model_selection_method": "all",
    "aggregation_method": "reward_based",
    "aggregation_level": "sentence",
    "model_selection_params": {},
    "aggregation_params": {
      "max_repeat": 3
    }
  },
  "max_rounds": 10,
  "score_threshold": -1.5,
  "max_tokens": 500
}'
```

### 5. ä»…ä½¿ç”¨æ¨¡å‹é€‰æ‹©ï¼ˆä¸èšåˆè¾“å‡ºï¼‰

```bash
curl -X POST "http://localhost:8000/v1/ensemble/presets/selection_only" \
-H "Content-Type: application/json" \
-d '{
  "prompt": "What is machine learning?",
  "model_selection_method": "zscore",
  "max_tokens": 300
}'
```

### 6. ä»…ä½¿ç”¨è¾“å‡ºèšåˆï¼ˆæ‰€æœ‰æ¨¡å‹ï¼‰

```bash
curl -X POST "http://localhost:8000/v1/ensemble/presets/aggregation_only" \
-H "Content-Type: application/json" \
-d '{
  "prompt": "Explain quantum computing",
  "aggregation_method": "round_robin",
  "aggregation_level": "sentence",
  "max_tokens": 400
}'
```

### 7. æ‰¹é‡æ¨ç†

```bash
curl -X POST "http://localhost:8000/v1/ensemble/batch" \
-H "Content-Type: application/json" \
-d '{
  "examples": [
    {
      "instruction": "You are a helpful assistant.",
      "input": "What is 5+5?",
      "ensemble_config": {
        "model_selection_method": "all",
        "aggregation_method": "reward_based"
      }
    },
    {
      "instruction": "You are a math expert.",
      "input": "What is 10Ã—10?",
      "ensemble_config": {
        "model_selection_method": "zscore",
        "aggregation_method": "random"
      }
    }
  ],
  "batch_size": 2
}'
```

## âš™ï¸ é…ç½®é€‰é¡¹

### æ¨¡å‹é€‰æ‹©æ–¹æ³• (model_selection_method)
- `"zscore"` - åŸºäº Z-score çš„æ¨¡å‹é€‰æ‹©ï¼ˆå›°æƒ‘åº¦å’Œç½®ä¿¡åº¦ï¼‰
- `"all"` - ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ¨¡å‹
- `"random"` - éšæœºé€‰æ‹©æ¨¡å‹å­é›†
- `"llm_blender"` - LLM-Blender æ–¹æ³•ï¼ˆå¦‚æœå®ç°ï¼‰

### è¾“å‡ºèšåˆæ–¹æ³• (aggregation_method)
- `"reward_based"` - åŸºäºå¥–åŠ±æ¨¡å‹åˆ†æ•°é€‰æ‹©è¾“å‡º
- `"random"` - éšæœºé€‰æ‹©ç”Ÿæˆçš„è¾“å‡º
- `"round_robin"` - è½®è¯¢é€‰æ‹©æ¨¡å‹è¾“å‡º

### èšåˆçº§åˆ« (aggregation_level)
- `"sentence"` - å¥å­/æ®µè½çº§åˆ«èšåˆï¼ˆç”Ÿæˆè¿‡ç¨‹ä¸­ï¼‰
- `"token"` - ä»¤ç‰Œçº§åˆ«èšåˆï¼ˆä¾‹å¦‚ GaCï¼‰
- `"response"` - å®Œæ•´å“åº”çº§åˆ«èšåˆï¼ˆä¾‹å¦‚æŠ•ç¥¨ï¼‰

## ğŸ”— Python å®¢æˆ·ç«¯ç¤ºä¾‹

```python
import requests

class EnsembleClient:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
    
    def chat_completion(self, prompt, ensemble_config=None, **kwargs):
        """å‘é€èŠå¤©å®Œæˆè¯·æ±‚"""
        payload = {
            "prompt": prompt,
            "ensemble_config": ensemble_config,
            **kwargs
        }
        response = requests.post(f"{self.base_url}/v1/chat/completions", json=payload)
        return response.json()
    
    def simple_ensemble(self, prompt, ensemble_method="reward_based", model_selection="all"):
        """ä½¿ç”¨ç®€å•é›†æˆé¢„è®¾"""
        payload = {
            "prompt": prompt,
            "ensemble_method": ensemble_method,
            "model_selection_method": model_selection
        }
        response = requests.post(f"{self.base_url}/v1/ensemble/presets/simple", json=payload)
        return response.json()

# ä½¿ç”¨ç¤ºä¾‹
client = EnsembleClient()

# åŸºç¡€è°ƒç”¨
result = client.chat_completion("What is artificial intelligence?")
print(result["choices"][0]["text"])

# è‡ªå®šä¹‰é…ç½®
config = {
    "model_selection_method": "zscore",
    "aggregation_method": "reward_based",
    "use_model_selection": True,
    "use_output_aggregation": True
}
result = client.chat_completion("Solve: 2x + 3 = 7", ensemble_config=config)
print(result["choices"][0]["text"])
```

## ğŸ“Š å“åº”æ ¼å¼

### Chat Completions å“åº”
```json
{
  "id": "cmpl-uuid",
  "object": "text_completion",
  "created": 1234567890,
  "model": "ensemble",
  "choices": [
    {
      "index": 0,
      "text": "ç”Ÿæˆçš„æ–‡æœ¬...",
      "finish_reason": "stop",
      "metadata": {
        "selected_models": ["model1", "model2"],
        "method": "zscore+reward_based",
        "ensemble_config": {...}
      }
    }
  ],
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 50,
    "total_tokens": 60
  }
}
```

### Ensemble Inference å“åº”
```json
{
  "id": "ensemble-uuid",
  "created": 1234567890,
  "result": {
    "output": "ç”Ÿæˆçš„æ–‡æœ¬...",
    "selected_models": ["model1", "model2"],
    "method": "zscore+reward_based",
    "config": {...}
  },
  "config": {...}
}
```

## ğŸ› ï¸ è¿è¡Œæ—¶é…ç½®æ›´æ–°

```bash
# æ›´æ–°æ¨¡å‹é…ç½®
curl -X POST "http://localhost:8000/v1/ensemble/config" \
-H "Content-Type: application/json" \
-d '{
  "model_specs": [
    {"path": "new-model-1", "engine": "hf", "device": "cuda:0"},
    {"path": "new-model-2", "engine": "hf", "device": "cuda:1"}
  ]
}'

# æ›´æ–°é»˜è®¤é›†æˆé…ç½®
curl -X POST "http://localhost:8000/v1/ensemble/config" \
-H "Content-Type: application/json" \
-d '{
  "default_ensemble_config": {
    "model_selection_method": "zscore",
    "aggregation_method": "reward_based",
    "use_model_selection": true,
    "use_output_aggregation": true
  }
}'
```

## ğŸ§ª æµ‹è¯• API

```bash
# è¿è¡Œ API æµ‹è¯•
python test/test_api.py

# æˆ–æ‰‹åŠ¨æµ‹è¯•å¥åº·æ£€æŸ¥
curl http://localhost:8000/status
```

## ğŸ› ï¸ æ•…éšœæ’é™¤

### vLLM CUDA å†…å­˜åˆ†é…é”™è¯¯

å¦‚æœä½ åœ¨ä½¿ç”¨ vLLM å¼•æ“æ—¶é‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š
```
captures_underway.empty() INTERNAL ASSERT FAILED at "/pytorch/c10/cuda/CUDACachingAllocator.cpp":3085
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ä¿®å¤ï¼ˆæ¨èï¼‰ï¼š**
   ```bash
   python -m ensemblehub.api --vllm_enforce_eager --vllm_disable_chunked_prefill
   ```

2. **åˆ‡æ¢åˆ° HuggingFace å¼•æ“ï¼š**
   ```bash
   # å°†æ¨¡å‹é…ç½®ä» "engine": "vllm" æ”¹ä¸º "engine": "hf"
   python -m ensemblehub.api --model_specs 'model_path:hf:cuda:0'
   ```

3. **ç¯å¢ƒå˜é‡è®¾ç½®ï¼š**
   ```bash
   export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
   python -m ensemblehub.api
   ```

### vLLM å±‚åç§°å†²çªé”™è¯¯

å¦‚æœä½ åœ¨ä½¿ç”¨ vLLM å¼•æ“æ—¶é‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š
```
Duplicate layer name: model.layers.X.self_attn.attn
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **ä½¿ç”¨ä¼˜åŒ–çš„ vLLM é…ç½®ï¼ˆæ¨èï¼‰ï¼š**
   ```bash
   # ä½¿ç”¨ LlamaFactory é£æ ¼çš„é…ç½®ï¼Œé€‚åˆå•å¡å¤§æ¨¡å‹
   python -m ensemblehub.api --ensemble_method random --model_selection_method all
   ```

2. **åˆ‡æ¢åˆ° HuggingFace å¼•æ“ï¼ˆæœ€ç¨³å®šï¼‰ï¼š**
   ```bash
   # å°†æ¨¡å‹é…ç½®ä» "engine": "vllm" æ”¹ä¸º "engine": "hf" 
   python -m ensemblehub.api --model_specs 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B:hf:cuda:0'
   ```

3. **è°ƒè¯•æ¨¡å¼è®¾ç½®ï¼š**
   ```bash
   # å¦‚æœä»æœ‰é—®é¢˜ï¼Œä½¿ç”¨è°ƒè¯•æ¨¡å¼å¯åŠ¨
   export CUDA_LAUNCH_BLOCKING=1
   python -m ensemblehub.api --ensemble_method random
   ```

### HuggingFace Meta Tensor é”™è¯¯

å¦‚æœä½ åœ¨ä½¿ç”¨ HuggingFace å¼•æ“æ—¶é‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š
```
Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to()
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **ä½¿ç”¨ eager attentionï¼ˆæ¨èï¼‰ï¼š**
   ```bash
   python -m ensemblehub.api --hf_use_eager_attention
   ```

2. **ç¦ç”¨ device_mapï¼š**
   ```bash
   python -m ensemblehub.api --hf_disable_device_map
   ```

3. **é™çº§ transformers ç‰ˆæœ¬ï¼š**
   ```bash
   pip install transformers==4.35.0
   python -m ensemblehub.api
   ```

4. **ä½¿ç”¨è‡ªåŠ¨è®¾å¤‡åˆ†é…ï¼š**
   ```bash
   # å°†è®¾å¤‡ä» "cuda:X" æ”¹ä¸º "auto"
   python -m ensemblehub.api --model_specs 'model_path:hf:auto'
   ```

### GPU å†…å­˜ä¸è¶³é”™è¯¯

å¦‚æœä½ é‡åˆ°ä»¥ä¸‹é”™è¯¯ï¼š
```
CUDA error: out of memory
```

**è§£å†³æ–¹æ¡ˆï¼š**

1. **ä½¿ç”¨é‡åŒ–å‡å°‘å†…å­˜å ç”¨ï¼ˆæ¨èï¼‰ï¼š**
   ```bash
   # ä½¿ç”¨ 8-bit é‡åŒ–
   python -m ensemblehub.api --hf_use_8bit
   
   # ä½¿ç”¨ 4-bit é‡åŒ–ï¼ˆæ›´èŠ‚çœå†…å­˜ï¼‰
   python -m ensemblehub.api --hf_use_4bit
   ```

2. **å‡å°‘åŒæ—¶åŠ è½½çš„æ¨¡å‹æ•°é‡ï¼š**
   ```bash
   # åªä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
   python -m ensemblehub.api --model_specs 'deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B:hf:cuda:0,deepseek-ai/DeepSeek-R1-Distill-Qwen-7B:hf:cuda:1'
   ```

3. **ä½¿ç”¨ CPU è¿è¡Œå¤§æ¨¡å‹ï¼š**
   ```bash
   # å°†å¤§æ¨¡å‹ç§»åˆ° CPU ä¸Š
   python -m ensemblehub.api --model_specs 'deepseek-ai/DeepSeek-R1-Distill-Qwen-32B:hf:cpu'
   ```

4. **æ¸…ç† GPU ç¼“å­˜ï¼š**
   ```bash
   # åœ¨è¿è¡Œå‰æ¸…ç† GPU ç¼“å­˜
   export CUDA_LAUNCH_BLOCKING=1
   python -c "import torch; torch.cuda.empty_cache()"
   python -m ensemblehub.api
   ```

### å¸¸è§é—®é¢˜

**Q: API å¯åŠ¨åæ— æ³•è®¿é—®ï¼Ÿ**
A: æ£€æŸ¥é˜²ç«å¢™è®¾ç½®ï¼Œç¡®ä¿ç«¯å£æœªè¢«å ç”¨ï¼š
```bash
curl http://localhost:8000/status
```

**Q: æ¨¡å‹åŠ è½½å¤±è´¥ï¼Ÿ**
A: æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œè®¾å¤‡é…ç½®ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU å†…å­˜ï¼š
```bash
nvidia-smi  # æ£€æŸ¥ GPU ä½¿ç”¨æƒ…å†µ
```

**Q: é›†æˆæ–¹æ³•é…ç½®æ— æ•ˆï¼Ÿ**
A: ç¡®ä¿ä½¿ç”¨ `python -m ensemblehub.api` è€Œä¸æ˜¯ `uvicorn` æ¥å¯åŠ¨ï¼š
```bash
# âœ… æ­£ç¡®
python -m ensemblehub.api --ensemble_method loop

# âŒ ä¸æ”¯æŒè‡ªå®šä¹‰é…ç½®
uvicorn ensemblehub.api:app --host 0.0.0.0 --port 8000
```

è¿™ä¸ªå¢å¼ºçš„ API æä¾›äº†å®Œå…¨çš„çµæ´»æ€§ï¼Œè®©ä½ å¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©å’Œé…ç½®ä¸åŒçš„é›†æˆæ–¹æ³•ï¼